# âœˆï¸ Flight Price Prediction â€“ End-to-End ML Pipeline

This project is a full-scale **end-to-end machine learning pipeline** for predicting flight prices. It's designed with modularity, scalability, and production-readiness in mind, using orchestration, experiment tracking, and real-time model serving.

---

## ðŸš€ Features

### ðŸ” End-to-End Pipeline
- **Data Ingestion**: Loads raw flight fare data from **Amazon S3** (can be extended to other sources).
- **Preprocessing**: Cleans, transforms, and encodes data.
- **Model Training**: Trains multiple ML models and selects the best one based on evaluation metrics.
- **Model Registry & Logging**: Uses **MLflow** to log experiments and register the best model.
- **Prediction Pipeline**: Automatically prepares incoming data for inference using trained transformers.
- **Artifact Storage**: Stores trained models and processors back in **S3**.

### âš™ï¸ Orchestration with Airflow
- All tasks are orchestrated using **Apache Airflow**.
- DAG defined in `airflow/dags/model_pipeline.py`.
- Airflow is protected using **FAB-based authentication**.
- DAG runs include ingestion, preprocessing, training, artifact upload, and more.

### ðŸŒ API Endpoint with FastAPI
- Serves model predictions via a REST endpoint at `/predict`.
- Uses **Pydantic** for strict input validation and schema enforcement.
- Deployed using **Uvicorn**.

### ðŸ“Š MLflow Tracking
- Tracks all experiment runs including parameters, metrics, and artifacts.
- MLflow UI available at `http://localhost:5000`.

---

## ðŸ§± Architecture

### Three services run simultaneously:

| Service     | Port  | Description                      |
|-------------|-------|----------------------------------|
| Airflow     | 8080  | Web UI for DAG orchestration     |
| FastAPI     | 8000  | Model prediction endpoint        |
| MLflow      | 5000  | Experiment tracking UI           |

> **Note**: Can be split into **separate microservices** and deployed on different instances for scale.

---

## ðŸŒ©ï¸ Deployment

### ðŸ³ Docker-Based

Everything runs via Docker. Just use:

```bash
bash run.sh
```

This script:
- Boots up Airflow with the configured DAG
- Starts MLflow tracking UI
- Launches the FastAPI app for inference

### ðŸ§ª Local Setup (Optional)

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Airflow standalone
airflow standalone

# Start API
uvicorn api.app:app --reload

# MLflow UI
mlflow ui
```

---

## ðŸ“¦ CI/CD

- Configured with **GitHub Actions** to build and deploy Docker image.
- Can be deployed to **AWS EC2** (or ECS) using shell or Terraform scripts.
- Example deployment (currently only API live due to RAM constraints on free tier):

ðŸ”— **Live API Endpoint:** [http://](API)

---

## ðŸ“ Project Structure

```
E2E/
â”‚
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ model_pipeline.py          # DAG for orchestrating the pipeline
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py                         # FastAPI app
â”‚   â””â”€â”€ request_model.py              # Pydantic model for input validation
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ data_collection.py
â”‚       â”œâ”€â”€ data_ingestion.py
â”‚       â”œâ”€â”€ data_preprocessing.py
â”‚       â”œâ”€â”€ model_training.py
â”‚       â”œâ”€â”€ predict_pipeline.py
â”‚       â””â”€â”€ handles3.py              # S3 utility functions
â”œâ”€â”€ notebooks/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.sh                             # Spins up Airflow, MLflow, and FastAPI
```

---

## ðŸ“ž Sample API Call

**POST `/predict`**

```json
{
  "airline": "SpiceJet",
  "source": "Delhi",
  "destination": "Mumbai",
  "departure_time": "Evening",
  "arrival_time": "Night",
  "duration": 2.5,
  "stops": "zero",
  "days_left":1,
  "class": "Economy"
}
```

**Response**

```json
{
  "price": 3456.78
}
```

## ðŸ§  Tech Stack

- **Python**
- **Apache Airflow**
- **MLflow**
- **FastAPI**
- **Docker**
- **AWS (EC2, S3)**
- **GitHub Actions**

---

## âœ… Highlights

- ðŸ”„ Modular pipeline with isolated components
- ðŸ” Automated with Airflow DAGs
- ðŸ” Transparent model tracking with MLflow
- ðŸ“¦ Dockerized for consistency
- ðŸŒ Real-time predictions via FastAPI
- ðŸš€ Deployed on AWS with CI/CD

---

## ðŸ“Œ Future Enhancements


- Add support for more data sources (e.g. PostgreSQL, APIs, Web Scrapping)
- Deploy each service as an independent microservice

---

## ðŸ™Œ Contributions

Open to improvements, ideas, or issues! Feel free to fork and raise a PR ðŸš€

---

> ðŸ’¡ Built to showcase end-to-end ML engineering and deployment skills with production-level architecture.